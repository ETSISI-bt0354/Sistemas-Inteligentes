{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Las **imágenes** a utilizar en este cuaderno son:\n",
        "\n",
        "- texto.jpg\n",
        "- sudoku.jpg\n",
        "- digito.jpg\n",
        "- senial_prohibido_90.jpg"
      ],
      "metadata": {
        "id": "1gs0LEytbSm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Montamos el Drive** de nuestro repositorio de Google para tener acceso a las imágenes que empleamos en este cuaderno:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jRUGB4p-bJ4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjynLCh2bEQA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Tesseract OCR**\n",
        "\n",
        "[Tesseract](https://pypi.org/project/pytesseract/) es una biblioteca de funciones en Python para el reconocimiento de texto (caracteres y digitos) en imágenes digitales (fue desarrollada originalmente por Hewlett-Packard y su desarrollo fue adquirido después por Google; por eso ahora se conoce como “Google Tesseract OCR”.\n",
        "\n",
        "Para aprender más usos y funcionalidades de Tesseract:\n",
        "[OCR using Pytesseract and OpenCV](https://nanonets.com/blog/ocr-with-tesseract/)\n",
        "\n",
        "Necesitamos instalar Tesseract para después poder importarlo en nuestro código.\n",
        "\n",
        "Lo instalamos haciendo uso de '!' para hacer llamadas al sistema (en este caso al comando sudo para poder llamar al comando apt para instalar Tesseract ya que el comando apt requiere permisos de root):\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "nCd1oiePbsaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "import pytesseract as pyt"
      ],
      "metadata": {
        "id": "1KWBCW28bzE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Ahora comprobamos los idiomas soportados por la instalación que hemos realizado\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "w4ZwVpuKsO3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\nLos idiomas soportados por Tesseract son: {pyt.get_languages()}')"
      ],
      "metadata": {
        "id": "tuABleD9oleb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Si no soporta el idioma español podemos instalarlo por separado y volvemos a comprobar si ya tiene soporte para español:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "la8kDU5Aozmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr-spa\n",
        "print(f'\\nLos idiomas soportados por Tesseract son: {pyt.get_languages()}')"
      ],
      "metadata": {
        "id": "SlOaCq7PpNby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Importamos el resto de librerias que vamos a necesitar en este cuaderno:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "eunGkWflfWJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "gAYhkILVfYg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Configuración:\n",
        "\n",
        "- OCR Engine Modes:\n",
        "\n",
        "  0    Legacy engine only.\n",
        "\n",
        "  1    Neural nets LSTM engine only.\n",
        "\n",
        "  2    Legacy + LSTM engines.\n",
        "\n",
        "  3    Default, based on what is available.\n",
        "\n",
        "- Page Segmentation Modes:\n",
        "\n",
        "  0    Orientation and script detection (OSD) only.\n",
        "\n",
        "  1    Automatic page segmentation with OSD.\n",
        "\n",
        "  2    Automatic page segmentation, but no OSD, or OCR.\n",
        "\n",
        "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
        "\n",
        "  4    Assume a single column of text of variable sizes.\n",
        "\n",
        "  5    Assume a single uniform block of vertically aligned text.\n",
        "\n",
        "  6    Assume a single uniform block of text.\n",
        "\n",
        "  7    Treat the image as a single text line.\n",
        "\n",
        "  8    Treat the image as a single word.\n",
        "\n",
        "  9    Treat the image as a single word in a circle.\n",
        "\n",
        " 10    Treat the image as a single character.\n",
        "\n",
        " 11    Sparse text. Find as much text as possible in no particular order.\n",
        "\n",
        " 12    Sparse text with OSD.\n",
        "\n",
        " 13    Raw line. Treat the image as a single text line bypassing hacks that are Tesseract-specific.\n",
        "\n",
        "OCR Engine modes: (see https://github.com/tesseract-ocr/tesseract/wiki#linux)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "PEYO2HR1u95P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejemplo 1**: Abrimos una imagen con sólo texto y lo probamos:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "OHhNr9AOcJzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Curso_24_25/imas/\"\n",
        "nombre_imagen = 'texto.jpg'\n",
        "path += nombre_imagen\n",
        "\n",
        "imgGris = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "_, binary = cv2.threshold(imgGris, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "print('Imagen Original')\n",
        "#cv2_imshow(imgGris)\n",
        "print('Imagen Binaria')\n",
        "#cv2_imshow(binary)\n",
        "\n",
        "# motor ocr por defecto (--oem 3) y un único bloque de texto (--psm 6)\n",
        "custom_config = r'--oem 3 --psm 6'\n",
        "\n",
        "# en el resultado obtenido de la imagen original le añadimos el\n",
        "# parámetro lang = spa para que reconozca en el idioma español\n",
        "print('\\nEl texto reconocido en la imagen original es: ')\n",
        "print(pyt.image_to_string(imgGris, lang = 'spa', config = custom_config))\n",
        "\n",
        "# en el resultado obtenido de la imagen binarizada dejarmos el idioma por defecto\n",
        "print('\\nEl texto reconocido en la imagen binaria es: ')\n",
        "print(pyt.image_to_string(binary, config=custom_config))\n"
      ],
      "metadata": {
        "id": "mOtaksz-cNbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Ejemplo 2**: Abrimos la imagen sudoku.jpg y lo probamos:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "UZs6uceafs5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Curso_24_25/imas/\"\n",
        "nombre_imagen = 'sudoku.jpg'\n",
        "path += nombre_imagen\n",
        "\n",
        "imgBGR = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "imgGris = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "print('Imagen Original')\n",
        "cv2_imshow(imgBGR)\n",
        "\n",
        "_, binary = cv2.threshold(imgGris, 60, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# motor ocr por defecto (--oem 3), un único bloque de texto (--psm 6)\n",
        "# y sólo dígitos (outputbase digits)\n",
        "custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
        "\n",
        "# obtenemos los dígitos presentes en la imagen con Tesseract\n",
        "digitos = pyt.image_to_string(binary, config=custom_config)\n",
        "\n",
        "# mostramos el resultado\n",
        "print(f'\\nLos dígitos reconocido en la imagen original son: {digitos}')\n"
      ],
      "metadata": {
        "id": "3Dmh0VnSfwZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Ejemplo 3**: Ahora abrimos la captura de una única celda del sudoku y lo probamos:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jxvHh37ucN0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract as pyt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "path = \"/content/drive/MyDrive/Curso_24_25/imas/\"\n",
        "nombre_imagen = 'digito.jpg'\n",
        "path += nombre_imagen\n",
        "\n",
        "imgBGR = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "imgRGB = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB)\n",
        "imgGris = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "_, binary = cv2.threshold(imgGris, 80, 255, cv2.THRESH_BINARY)\n",
        "_, binary_inv = cv2.threshold(imgGris, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "_, trunc = cv2.threshold(imgGris, 80, 255, cv2.THRESH_TRUNC)\n",
        "_, tozero = cv2.threshold(imgGris, 80, 255, cv2.THRESH_TOZERO)\n",
        "_, tozero_inv = cv2.threshold(imgGris, 80, 255, cv2.THRESH_TOZERO_INV)\n",
        "\n",
        "titulos = ['Imagen Original', 'Imagen Binaria',\n",
        "\t'Imagen Binaria Inversa', 'Imagen Truncada',\n",
        "  'Imagen Tozero', 'Imagen Tozero Inversa']\n",
        "\n",
        "imagenes = [imgGris, binary, binary_inv, trunc, tozero, tozero_inv]\n",
        "\n",
        "for i in range(len(imagenes)):\n",
        "\tplt.subplot(3, 3, i+1), plt.imshow(imagenes[i], 'gray')\n",
        "\tplt.title(titulos[i])\n",
        "\tplt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# motor ocr por defecto (--oem 3), un único carácter (--psm 10)\n",
        "# y sólo dígitos (outputbase digits)\n",
        "custom_config = r'--oem 3 --psm 10 outputbase digits'\n",
        "print(f'\\nEl dígito reconocido en la imagen original es: {pyt.image_to_string(imgGris, config=custom_config)}')\n",
        "print(f'El dígito reconocido en la imagen binaria es: {pyt.image_to_string(binary, config=custom_config)}')\n"
      ],
      "metadata": {
        "id": "JQUrS31UcU-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Ejemplo 4**: Reconocer valores numéricos en una imagen de una señal de tráfico:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "F4mHzZpPmMQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Curso_24_25/imas/\"\n",
        "nombre_imagen = 'senial_prohibido_90.jpg'\n",
        "path += nombre_imagen\n",
        "\n",
        "imgBGR = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "imgGris = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "print('Imagen Original: \\n')\n",
        "cv2_imshow(imgBGR)\n",
        "\n",
        "_, binary = cv2.threshold(imgGris, 60, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# configuramos pytesseract para que detecte sólo dígitos\n",
        "custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
        "\n",
        "# otra forma de hacerlo consiste en especificar los caracteres a reconocer\n",
        "# custom_config = r'--oem 3 --psm 6 tessedit_char_whitelist=0123456789'\n",
        "\n",
        "# obtenemos los dígitos presentes en la imagen con Tesseract\n",
        "digitos = pyt.image_to_string(binary, config=custom_config)\n",
        "\n",
        "# mostramos el resultado\n",
        "print(f'\\nLos dígitos reconocidos en la imagen original son: {digitos}')\n",
        "print(f'Por lo tanto, se trata de una señal de prohibido circular a más de {int(digitos)} km/h')\n"
      ],
      "metadata": {
        "id": "TpmAoH2PmQNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **EJERCICIO 1**: Reconocer texto en carteles informátivos de tráfico\n",
        "\n",
        "- Probar el funcionamiento del OCR para distintos carteles informátivos de tráfico\n",
        "\n",
        "- Probar lo mismo con otras librerías OCR en Python (EasyOCR, docTR, Keras-OCR, Aspose.OCR, ...)\n",
        "\n",
        "  https://www.analyticsvidhya.com/blog/2024/04/ocr-libraries-in-python/\n",
        "\n",
        "  https://blog.aspose.com/es/ocr/python-ocr-library/\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vo_vD2Tk581x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvqSK6Hvrpcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}